---
title: "Textual Analysis"
author: "Matthias Uckert"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

    # github_document:
    # toc: true
    # toc_depth: 2

# Description

xxx

```{r setup, include=FALSE, purl=FALSE}
knitr::opts_knit$set(root.dir = normalizePath(here::here())) 
knitr::opts_chunk$set(root.dir = normalizePath(here::here())) 
```

# Script Setup

```{r message=FALSE, warning=FALSE}
library(tidyverse); library(tidytext); library(readtext); library(furrr)
library(fst); library(stringi); library(ISOcodes); library(scales)

source("1_code/00_functions/f-all.R")
source("1_code/00_functions/f-textual_analysis.R")

.workers <- min(availableCores() / 2, 16)
```

# Code

## Paths
```{r}
lst_paths <- list(
  dir_main = "2_output/03_textual_analysis",
  dir_pdf = "2_output/02_get_arcom_data/documents/",
  dir_sec = "2_output/01_get_edgar_data/documents/",
  path_pdf_data = "2_output/02_get_arcom_data/arcom_firm_data.rds",
  path_sec_data = "2_output/01_get_edgar_data/txt_download.rds",
  dir_token = "2_output/03_textual_analysis/token",
  path_stop = "2_output/03_textual_analysis/lm_stop.rds"
) %>% create_dirs()

```

## List Files
```{r}
tab_files_pdf <- list_files_tab(lst_paths$dir_pdf, reg = "pdf$")
tab_files_sec <- list_files_tab(lst_paths$dir_sec, reg = "zip$") %>%
  filter(startsWith(doc_id, "txt"))
```

## Read Tables
```{r}
tab_pdf_data <- read_rds(lst_paths$path_pdf_data) %>%
  select(-isin)

tab_sec_data <- read_rds(lst_paths$path_sec_data) %>%
  mutate(doc_id = paste0(file_ext, "_", symbol, "-", year)) %>%
  select(doc_id, year, company = company_name) %>%
  mutate(country_code = "USA") %>%
  left_join(select(ISO_3166_1, country_code = Alpha_3, country = Name), by = "country_code")

tab_data <- bind_rows(tab_pdf_data, tab_sec_data) %>%
  mutate(country = if_else(!country == "United States", "Europe", country))
rm(tab_pdf_data, tab_sec_data)

```


```{r}
set.seed(123)
tab_files <- bind_rows(tab_files_pdf, tab_files_sec) %>%
  left_join(select(tab_data, doc_id, country, year, company), by = "doc_id") %>%
  filter(!is.na(country)) %>%
  filter(between(year, 2006, 2015)) %>%
  group_by(company) %>%
  filter(all(2006:2015 %in% year)) %>%
  distinct(company, year, .keep_all = TRUE)


tab_files %>%
  group_by(country) %>%
  summarise(n_firm = n_distinct(company), n_doc = n(), .groups = "drop")

tmp <- distinct(tab_files, country, company) %>%
  group_by(country) %>%
  slice_sample(n = 2) %>%
  ungroup()

tab_files <- inner_join(tab_files, tmp, by = c("country", "company"))

tab_files %>%
  group_by(country) %>%
  summarise(n_firm = n_distinct(company), n_doc = n(), .groups = "drop")

tab_files_pdf <- filter(tab_files, country == "Europe")
tab_files_sec <- filter(tab_files, country == "United States")
```






```{r message=FALSE, warning=FALSE}
.prc <- list_files_tab(lst_paths$dir_token)
tab_files_pdf_use <- filter(tab_files_pdf, !doc_id %in% .prc$doc_id)

if (nrow(tab_files_pdf_use) > 0) {
  plan("multisession", workers = .workers)
  future_walk(
    .x = tab_files_pdf_use$path,
    .f = ~ pdf_read_and_tokenize(.x, lst_paths$dir_token),
    .options = furrr_options(seed = TRUE),
    .progress = TRUE
  )
  plan("default")
}

rm(tab_files_pdf_use)

```


```{r message=FALSE, warning=FALSE}
.prc <- list_files_tab(lst_paths$dir_token)
tab_files_sec_use <- filter(tab_files_sec, !doc_id %in% .prc$doc_id)


if (nrow(tab_files_sec_use) > 0) {
  plan("multisession", workers = .workers)
  future_walk(
    .x = tab_files_sec_use$path,
    .f = ~ sec_read_and_tokenize(.x, lst_paths$dir_token),
    .options = furrr_options(seed = TRUE),
    .progress = TRUE
  )
  plan("default")
}
rm(tab_files_sec_use)

```


```{r}
files_token <- list_files_tab(lst_paths$dir_token) %>%
  filter(doc_id %in% tab_files$doc_id)
```



```{r}
.path_lm_stop <- "2_output/03_textual_analysis/lm_stop.rds"
if (!file.exists(lst_paths$path_stop)) {
  tab_lm_stop <- get_lm_stop()
  write_rds(tab_lm_stop, lst_paths$path_stop)
} else {
  tab_lm_stop <- read_rds(lst_paths$path_stop)
}
```

## Get Ngrams
```{r}
plan("multisession", workers = .workers)
tab_1gram <- future_map_dfr(
  .x = set_names(files_token$path, files_token$doc_id),
  .f = ~ get_ngrams(.x, 1, tab_lm_stop, TRUE),
  .options = furrr_options(seed = TRUE),
  .progress = TRUE,
  .id = "doc_id"
)
tab_2gram <- future_map_dfr(
  .x = set_names(files_token$path, files_token$doc_id),
  .f = ~ get_ngrams(.x, 2, tab_lm_stop, TRUE),
  .options = furrr_options(seed = TRUE),
  .progress = TRUE,
  .id = "doc_id"
)
plan("default")
```


## Analysis by Country
```{r}
prep_top_n_by(tab_1gram, tab_data, country, 20) %>%
  display_top_n_by(country)
```

```{r}
prep_top_n_by(tab_2gram, tab_data, country, 20) %>%
  display_top_n_by(country)
```

## Analysis by Year
```{r}
prep_top_n_by(tab_1gram, tab_data, year, 20) %>%
  filter(year %in% c(2005, 2010, 2015, 2020)) %>%
  display_top_n_by(year)
```

## Compare 
```{r}
tab_2gram %>%
  left_join(select(tab_data, doc_id, country), by = "doc_id") %>%
  group_by(country, word) %>%
  summarise(n = sum(n), .groups = "drop_last") %>%
  mutate(p = n / sum(n, na.rm = TRUE)) %>%
  ungroup() %>%
  select(-n) %>%
  pivot_wider(names_from = country, values_from = p) %>%
  filter(!is.na(Europe) & !is.na(`United States`)) %>%
  filter(Europe > .00001 | `United States` > .00001) %>%
  ggplot(aes(x = `United States`, y = Europe)) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3, color = "blue") +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "lightblue", high = "blue") +
  theme(legend.position="none") +
  theme_bw()
  
```

## Sentiment
```{r}
tab_1gram %>%
  left_join(get_sentiments("loughran"), by = "word") %>%
  left_join(select(tab_data, doc_id, country, year), by = "doc_id") %>%
  group_by(country, year, sentiment) %>%
  summarise(n = sum(n), .groups = "drop_last") %>%
  mutate(p = n / sum(n)) %>%
  filter(sentiment %in% c("positive", "negative")) %>%
  mutate(p = if_else(sentiment == "negative", -p, p)) %>%
  ggplot(aes(x = year, y = p, color = sentiment, fill = sentiment)) +
  geom_area(stat = "identity", alpha = 0.4) +
  geom_point(size = 1) +
  facet_wrap(~country, nrow = 1) +
  theme_bw() +
  labs(x = NULL, y = NULL) +
  geom_vline(xintercept = c(2009)) +
  theme(legend.position = "none")
```

## Uncertainty
```{r}
tab_1gram %>%
  left_join(get_sentiments("loughran"), by = "word") %>%
  left_join(select(tab_data, doc_id, country, year), by = "doc_id") %>%
  group_by(country, year, sentiment) %>%
  summarise(n = sum(n), .groups = "drop_last") %>%
  mutate(p = n / sum(n)) %>%
  filter(sentiment %in% c("uncertainty")) %>%
  mutate(p = if_else(sentiment == "negative", -p, p)) %>%
  ggplot(aes(x = year, y = p, color = "grey", fill = "grey")) +
  geom_area(stat = "identity", alpha = 0.4) +
  geom_point(size = 1) +
  facet_wrap(~country, nrow = 1) +
  theme_bw() +
  labs(x = NULL, y = NULL) +
  geom_vline(xintercept = c(2009)) +
  theme(legend.position = "none")
```

