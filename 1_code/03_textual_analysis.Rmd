---
title: "Textual Analysis"
author: "Matthias Uckert"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_notebook
---

    # github_document:
    # toc: true
    # toc_depth: 2

# Description

xxx

```{r setup, include=FALSE, purl=FALSE}
knitr::opts_knit$set(root.dir = normalizePath(here::here())) 
knitr::opts_chunk$set(root.dir = normalizePath(here::here())) 
```

# Script Setup

```{r message=FALSE, warning=FALSE}
library(tidyverse); library(tidytext); library(readtext); library(furrr)
library(fst); library(stringi); library(ISOcodes); library(scales)

.dir_main <- "2_output/03_textual_analysis"
if(!dir.exists(.dir_main)) dir.create(.dir_main, recursive = TRUE)

source("1_code/00_functions/f-all.R")
source("1_code/00_functions/f-textual_analysis.R")
```

# Code

## Paths
```{r}
.dir_pdf <- "2_output/02_get_arcom_data/documents/"
.dir_sec <- "2_output/01_get_edgar_data/documents/"

.path_pdf_data <- "2_output/02_get_arcom_data/arcom_firm_data.rds"
.path_sec_data <- "2_output/01_get_edgar_data/txt_download.rds"
```

## List Files
```{r}
tab_files_pdf <- list_files_tab(.dir_pdf, reg = "pdf$")
tab_files_sec <- list_files_tab(.dir_sec, reg = "zip$") %>%
  filter(startsWith(doc_id, "txt"))
```

## Read Tables
```{r}
tab_pdf_data <- read_rds(.path_pdf_data) %>%
  select(-isin)
tab_sec_data <- read_rds(.path_sec_data) %>%
  mutate(doc_id = paste0(file_ext, "_", symbol, "-", year)) %>%
  select(doc_id, year, company = company_name) %>%
  mutate(country_code = "USA") %>%
  left_join(select(ISO_3166_1, country_code = Alpha_3, country = Name), by = "country_code")

tab_data <- bind_rows(tab_pdf_data, tab_sec_data) %>%
  mutate(country = if_else(!country == "United States", "Europe", country))
rm(tab_pdf_data, tab_sec_data)

```



```{r message=FALSE, warning=FALSE}
.dir_token <- "2_output/03_textual_analysis/token"
if (!dir.exists(.dir_token)) dir.create(.dir_token)
.prc <- list_files_tab(.dir_token)
tab_files_pdf_use <- filter(tab_files_pdf, !doc_id %in% .prc$doc_id)


plan("multisession", workers = 8)
future_walk(
  .x = tab_files_pdf_use$path,
  .f = ~ pdf_read_and_tokenize(.x, .dir_token),
  .options = furrr_options(seed = TRUE),
  .progress = TRUE
)
plan("default")
```


```{r message=FALSE, warning=FALSE}
.dir_token <- "2_output/03_textual_analysis/token"
if (!dir.exists(.dir_token)) dir.create(.dir_token)
.prc <- list_files_tab(.dir_token)
tab_files_sec_use <- filter(tab_files_sec, !doc_id %in% .prc$doc_id)


plan("multisession", workers = 4)
future_walk(
  .x = tab_files_sec_use$path,
  .f = ~ sec_read_and_tokenize(.x, .dir_token),
  .options = furrr_options(seed = TRUE),
  .progress = TRUE
)
plan("default")
```



```{r}
.path_lm_stop <- "2_output/03_textual_analysis/lm_stop.rds"
if (!file.exists(.path_lm_stop)) {
  tab_lm_stop <- get_lm_stop()
  write_rds(tab_lm_stop, .path_lm_stop)
} else {
  tab_lm_stop <- read_rds(.path_lm_stop)
}
```


```{r}
set.seed(123)
files_token <- list_files_tab(.dir_token) %>%
  mutate(
    type = if_else(startsWith(doc_id, "txt_"), "sec", "int")
  ) %>%
  left_join(select(tab_data, doc_id, country), by = "doc_id") %>%
  filter(!is.na(country)) %>%
  group_by(country) %>%
  slice_sample(n = 10) %>%
  ungroup()
```


## Get Ngrams
```{r}
plan("multisession", workers = 8)
tab_1gram <- future_map_dfr(
  .x = set_names(files_token$path, files_token$doc_id),
  .f = ~ get_ngrams(.x, 1, tab_lm_stop, TRUE),
  .options = furrr_options(seed = TRUE),
  .progress = TRUE,
  .id = "doc_id"
)
tab_2gram <- future_map_dfr(
  .x = set_names(files_token$path, files_token$doc_id),
  .f = ~ get_ngrams(.x, 2, tab_lm_stop, TRUE),
  .options = furrr_options(seed = TRUE),
  .progress = TRUE,
  .id = "doc_id"
)
plan("default")
```


## Analysis by Country
```{r}
prep_top_n_by(tab_1gram, tab_data, country, 20) %>%
  display_top_n_by(country)
```

```{r}
prep_top_n_by(tab_2gram, tab_data, country, 20) %>%
  display_top_n_by(country)
```

## Analysis by Year
```{r}
prep_top_n_by(tab_1gram, tab_data, year, 20) %>%
  filter(year %in% c(2005, 2010, 2015, 2020)) %>%
  display_top_n_by(year)
```

## Compare 
```{r}
tab_2gram %>%
  left_join(select(tab_data, doc_id, country), by = "doc_id") %>%
  group_by(country, word) %>%
  summarise(n = sum(n), .groups = "drop_last") %>%
  mutate(p = n / sum(n, na.rm = TRUE)) %>%
  ungroup() %>%
  select(-n) %>%
  filter(p >= .0001) %>%
  pivot_wider(names_from = country, values_from = p) %>%
  filter(!is.na(Europe) & !is.na(`United States`)) %>%
  ggplot(aes(x = `United States`, y = Europe)) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3, color = "blue") +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "lightblue", high = "blue") +
  theme(legend.position="none") +
  theme_bw()
  
```

## Sentiment
```{r}
tab_1gram %>%
  left_join(get_sentiments("loughran"), by = "word") %>%
  left_join(select(tab_data, doc_id, country, year), by = "doc_id") %>%
  group_by(country, year, sentiment) %>%
  summarise(n = sum(n), .groups = "drop_last") %>%
  mutate(p = n / sum(n)) %>%
  filter(sentiment %in% c("positive", "negative")) %>%
  mutate(p = if_else(sentiment == "negative", -p, p)) %>%
  ggplot(aes(x = year, y = p, color = sentiment, fill = sentiment)) +
  geom_area(stat = "identity", alpha = 0.4) +
  geom_point(size = 1) +
  facet_wrap(~country, nrow = 1) +
  theme_bw() +
  labs(x = NULL, y = NULL) +
  geom_vline(xintercept = c(2009)) +
  theme(legend.position = "none")
```

## Uncertainty
```{r}
tab_1gram %>%
  left_join(get_sentiments("loughran"), by = "word") %>%
  left_join(select(tab_data, doc_id, country, year), by = "doc_id") %>%
  group_by(country, year, sentiment) %>%
  summarise(n = sum(n), .groups = "drop_last") %>%
  mutate(p = n / sum(n)) %>%
  filter(sentiment %in% c("uncertainty")) %>%
  mutate(p = if_else(sentiment == "negative", -p, p)) %>%
  ggplot(aes(x = year, y = p, color = "grey", fill = "grey")) +
  geom_area(stat = "identity", alpha = 0.4) +
  geom_point(size = 1) +
  facet_wrap(~country, nrow = 1) +
  theme_bw() +
  labs(x = NULL, y = NULL) +
  geom_vline(xintercept = c(2009)) +
  theme(legend.position = "none")
```

